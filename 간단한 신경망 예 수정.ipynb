{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # 판다스 라이브러리\n",
    "import csv # csv 라이브러리\n",
    "\n",
    "\n",
    "tr = pd.read_csv(\"student.csv\", encoding = 'utf-8')\n",
    "\n",
    "\n",
    "student_x_data = tr.loc[:, ['age','activities','famsup','paid','internet','Medu','Fedu','studytime','schoolsup','G3']]\n",
    "student_y_data = tr.loc[:,['pass']]\n",
    "\n",
    "\n",
    "#,'G1','G2','G3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>activities</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>internet</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>studytime</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  activities  famsup  paid  internet  Medu  Fedu  studytime  schoolsup  \\\n",
       "0   18           0       0     0         0     4     4          2          1   \n",
       "1   17           0       1     0         1     1     1          2          0   \n",
       "2   15           0       0     1         1     1     1          2          1   \n",
       "3   15           1       1     1         1     4     2          3          0   \n",
       "4   16           0       1     1         0     3     3          2          0   \n",
       "\n",
       "   G3  \n",
       "0   6  \n",
       "1   6  \n",
       "2  10  \n",
       "3  15  \n",
       "4  10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pass\n",
       "0     0\n",
       "1     0\n",
       "2     1\n",
       "3     1\n",
       "4     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  activities  famsup  paid  internet  Medu  Fedu  studytime  \\\n",
      "0     18           0       0     0         0     4     4          2   \n",
      "1     17           0       1     0         1     1     1          2   \n",
      "2     15           0       0     1         1     1     1          2   \n",
      "3     15           1       1     1         1     4     2          3   \n",
      "4     16           0       1     1         0     3     3          2   \n",
      "..   ...         ...     ...   ...       ...   ...   ...        ...   \n",
      "390   20           0       1     1         0     2     2          2   \n",
      "391   17           0       0     0         1     3     1          1   \n",
      "392   21           0       0     0         0     1     1          1   \n",
      "393   18           0       0     0         1     3     2          1   \n",
      "394   19           0       0     0         1     1     1          1   \n",
      "\n",
      "     schoolsup  G3  \n",
      "0            1   6  \n",
      "1            0   6  \n",
      "2            1  10  \n",
      "3            0  15  \n",
      "4            0  10  \n",
      "..         ...  ..  \n",
      "390          0   9  \n",
      "391          0  16  \n",
      "392          0   7  \n",
      "393          0  10  \n",
      "394          0   9  \n",
      "\n",
      "[395 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "result_x=[]\n",
    "for i in student_x_data.values:\n",
    "    result_x.append(list(i))\n",
    "\n",
    "result_y=[]\n",
    "for i in student_y_data.values:\n",
    "    result_y.append(list(i))\n",
    "\n",
    "\n",
    "print(student_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mraen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 데이터 (입력 x, 라벨 y)\n",
    "x_train = torch.FloatTensor(result_x)\n",
    "y_train = torch.FloatTensor(result_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 구조 모델링\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10,64), # 입력계층 = 1, 은닉계층1 = 5\n",
    "    nn.ReLU(), # ReLu 활성화 함수\n",
    "    nn.Linear(64,32), # 은닉 계층2 = 3\n",
    "    nn.ReLU(), # ReLu 활성화 함수\n",
    "    nn.Linear(32,2), # 출력계층 = 1\n",
    ")\n",
    "\n",
    "# optimizer 설정, 경사 하강법 SGD를 사용하고 학습 속도를 의미하는 lr은 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mraen\\AppData\\Local\\Temp\\ipykernel_8168\\3430858516.py:10: UserWarning: Using a target size (torch.Size([395, 1])) that is different to the input size (torch.Size([395, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  cost = F.mse_loss(prediction, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/300 Cost:0.865101\n",
      "Epoch   10/300 Cost:0.117363\n",
      "Epoch   20/300 Cost:0.107510\n",
      "Epoch   30/300 Cost:0.100861\n",
      "Epoch   40/300 Cost:0.095860\n",
      "Epoch   50/300 Cost:0.091934\n",
      "Epoch   60/300 Cost:0.088877\n",
      "Epoch   70/300 Cost:0.086538\n",
      "Epoch   80/300 Cost:0.084752\n",
      "Epoch   90/300 Cost:0.083360\n",
      "Epoch  100/300 Cost:0.082397\n",
      "Epoch  110/300 Cost:0.081553\n",
      "Epoch  120/300 Cost:0.080822\n",
      "Epoch  130/300 Cost:0.080169\n",
      "Epoch  140/300 Cost:0.079543\n",
      "Epoch  150/300 Cost:0.078951\n",
      "Epoch  160/300 Cost:0.078382\n",
      "Epoch  170/300 Cost:0.077835\n",
      "Epoch  180/300 Cost:0.077322\n",
      "Epoch  190/300 Cost:0.076801\n",
      "Epoch  200/300 Cost:0.076263\n",
      "Epoch  210/300 Cost:0.075675\n",
      "Epoch  220/300 Cost:0.075020\n",
      "Epoch  230/300 Cost:0.074492\n",
      "Epoch  240/300 Cost:0.073984\n",
      "Epoch  250/300 Cost:0.073493\n",
      "Epoch  260/300 Cost:0.073022\n",
      "Epoch  270/300 Cost:0.072573\n",
      "Epoch  280/300 Cost:0.072135\n",
      "Epoch  290/300 Cost:0.071719\n"
     ]
    }
   ],
   "source": [
    "# 학습 수행, epochs = 100\n",
    "n_epochs = 300\n",
    "\n",
    "# 경사 하강법을 100회 반복\n",
    "for epoch in range(n_epochs):\n",
    "    # 모델을 통한 예측 값 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # 손실 함수(평균 제곱 오차 함수) 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # 파라미터의 기울기(gradient)를 누적시키지 않고 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 비용 함수를 미분하여 기울기 계산\n",
    "    cost.backward() # 기울기 계산 (역전파)\n",
    "    \n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 10번 반복마다 로그 출력\n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch {:4d}/{} Cost:{:.6f}'.format(epoch, n_epochs, cost.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y: tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "predict: tensor([ 0.2189,  0.1555,  0.2801,  0.2130,  0.7288,  0.6606,  1.0062,  0.9869,\n",
      "         0.6385,  0.6804,  1.0536,  1.0266,  0.8097,  0.8118,  0.2060,  0.1742,\n",
      "         1.1849,  1.2200,  1.0510,  1.0641,  0.4950,  0.6073,  0.8540,  0.8286,\n",
      "         0.9965,  0.9677,  0.7257,  0.7879,  1.0307,  1.1173,  0.9930,  1.0159,\n",
      "         0.9919,  1.0001,  0.6724,  0.5467,  0.0678,  0.0584,  0.6091,  0.6065,\n",
      "         0.9982,  1.0157,  1.0306,  1.0393,  1.0782,  1.0272,  0.9044,  0.8720,\n",
      "         0.5061,  0.4947,  0.4296,  0.4620,  0.7809,  0.8069,  0.9904,  0.9609,\n",
      "         0.7848,  0.6918,  0.7086,  0.7453,  0.8192,  0.8875,  1.1332,  1.1442,\n",
      "         1.0653,  1.0608,  0.8754,  0.8210,  1.0168,  1.0231,  0.2559,  0.2069,\n",
      "         1.1585,  1.1726,  1.0716,  1.0459,  0.7656,  0.7475,  0.9301,  0.8049,\n",
      "         0.8223,  0.7704,  0.8268,  0.8415,  1.1816,  1.1955,  0.8050,  0.7579,\n",
      "         0.6225,  0.4862,  0.1827,  0.1469,  0.7791,  0.7860,  1.2782,  1.2788,\n",
      "         0.9243,  0.9036,  0.3383,  0.2764,  0.9233,  0.9660,  0.8849,  0.9026,\n",
      "         0.6291,  0.5808,  0.7130,  0.7284,  0.9152,  0.9197,  0.6964,  0.6340,\n",
      "         1.0270,  1.0047,  1.0229,  0.9946,  0.6563,  0.5483,  1.0536,  1.0784,\n",
      "         0.7207,  0.6834,  0.8121,  0.7117,  0.6529,  0.5294,  0.4980,  0.4713,\n",
      "         0.6603,  0.5404,  1.0481,  1.0312,  0.8279,  0.8125,  0.2566,  0.2231,\n",
      "         0.4769,  0.4607,  1.0032,  1.0702,  0.9922,  1.0413,  0.6577,  0.6488,\n",
      "         0.2028,  0.1115,  0.9561,  0.8665,  0.7658,  0.7133,  0.6168,  0.6401,\n",
      "         0.6193,  0.5439,  0.8165,  0.8356,  0.6753,  0.5389,  0.1677,  0.2033,\n",
      "         0.8961,  0.8134,  0.8136,  0.8016,  0.1839,  0.2470,  1.0198,  0.9986,\n",
      "         0.7461,  0.6878,  0.4189,  0.4987,  0.2377,  0.2143,  0.9608,  0.9319,\n",
      "         0.7133,  0.6648,  0.3139,  0.3523,  0.4240,  0.5069,  1.1791,  1.1175,\n",
      "         0.2117,  0.1026,  0.5928,  0.5895,  0.9621,  0.9757,  0.7388,  0.6819,\n",
      "         1.0665,  0.9582,  0.6693,  0.6464,  1.0072,  0.9546,  0.3905,  0.4155,\n",
      "         0.0882,  0.0936,  1.1564,  1.1686,  0.9990,  0.9620,  0.1996,  0.1970,\n",
      "         1.1962,  1.2146,  0.7849,  0.7193,  0.4973,  0.4943,  1.1861,  1.2186,\n",
      "         0.8911,  0.9145,  1.1162,  1.1208,  1.2484,  1.2155,  0.6955,  0.5964,\n",
      "         0.9592,  0.8753,  1.1912,  1.1720,  0.6265,  0.5274,  1.1100,  1.1110,\n",
      "         0.9821,  0.9348,  0.9454,  0.8998,  0.5312,  0.4598,  0.9147,  0.9553,\n",
      "         0.9931,  1.0523,  1.0092,  1.0441,  0.9827,  0.9805,  0.9245,  0.8839,\n",
      "         0.4651,  0.4786,  0.8553,  0.8168,  0.7917,  0.6858,  0.5823,  0.5445,\n",
      "        -0.2353, -0.1517,  1.2218,  1.1732, -0.1437, -0.0890, -0.2055, -0.1742,\n",
      "         0.8493,  0.8949,  0.7499,  0.7724, -0.2039, -0.0622, -0.1559, -0.0848,\n",
      "        -0.1637, -0.0660, -0.2523, -0.1132,  0.8280,  0.8356,  1.0388,  1.0124,\n",
      "        -0.1032, -0.1245,  0.5837,  0.5141,  0.7214,  0.7622,  0.8751,  0.9087,\n",
      "        -0.2072, -0.1907,  0.7589,  0.7877, -0.1968, -0.1440,  0.7864,  0.8567,\n",
      "        -0.2334, -0.0774,  0.6783,  0.6741, -0.1338, -0.1977,  0.9595,  0.8941,\n",
      "         0.6769,  0.6963, -0.2310, -0.1657,  0.8137,  0.7519,  0.5009,  0.4116,\n",
      "         0.9022,  0.9369,  0.6632,  0.5752,  0.9960,  1.0000,  0.8730,  0.9137,\n",
      "        -0.1770, -0.1878,  0.3395,  0.2875, -0.1581, -0.1290,  0.7098,  0.7373,\n",
      "         0.4084,  0.2772,  0.8542,  0.7804,  0.7109,  0.7056,  1.0599,  1.0510,\n",
      "        -0.1981, -0.1148,  0.9883,  1.0372, -0.2463, -0.0772,  1.0460,  1.0307,\n",
      "         0.5841,  0.6339, -0.1393, -0.1059,  0.5313,  0.5460,  0.4884,  0.4918,\n",
      "         0.8155,  0.7747,  0.2420,  0.1680,  0.4885,  0.4379,  0.7279,  0.6870,\n",
      "         0.3601,  0.3981,  0.8771,  0.8429,  1.1669,  1.2007,  0.4283,  0.3896,\n",
      "         0.8630,  0.8841,  0.7839,  0.7293,  0.8056,  0.8048,  1.0230,  0.9863,\n",
      "         0.5420,  0.5578,  0.7089,  0.6974,  0.9342,  0.9776,  0.6135,  0.5193,\n",
      "         0.5069,  0.4413,  0.6677,  0.6176,  0.9695,  1.0224,  1.0964,  1.0979,\n",
      "         1.1129,  1.1336,  0.6366,  0.6381,  1.2149,  1.2375,  0.5950,  0.6972,\n",
      "         1.0926,  1.0827,  0.6969,  0.6121,  0.6702,  0.6612,  0.2028,  0.1907,\n",
      "         0.7987,  0.7943,  0.5293,  0.6295,  0.2856,  0.3004,  0.9219,  0.8926,\n",
      "         0.6595,  0.6370,  0.2610,  0.2891,  0.3903,  0.4091,  0.9114,  0.9755,\n",
      "         0.9959,  0.9726,  0.4179,  0.3917,  0.5590,  0.6370,  1.0393,  1.0464,\n",
      "         0.0563,  0.0419,  0.3682,  0.4426,  0.4145,  0.4453,  0.6956,  0.6624,\n",
      "         0.2308,  0.1507, -0.1475, -0.1384,  1.1553,  1.1485,  0.9482,  0.9928,\n",
      "         1.0105,  0.9823,  0.3148,  0.1890,  1.0587,  1.0223,  0.8937,  0.9489,\n",
      "         0.5418,  0.4403,  0.9014,  0.8397,  1.0171,  0.9605,  0.7964,  0.7635,\n",
      "         0.5014,  0.4473,  0.9131,  0.9314,  0.2784,  0.2611,  0.7157,  0.6215,\n",
      "         0.9734,  0.9399,  0.8269,  0.8363,  0.7926,  0.6892, -0.1384, -0.1558,\n",
      "         0.8531,  0.7734,  0.8034,  0.8813, -0.2096, -0.1184,  0.8282,  0.7774,\n",
      "        -0.1621, -0.1466,  1.1368,  1.1497,  0.9215,  0.9893,  0.3712,  0.2277,\n",
      "         0.1110,  0.1218,  1.0419,  1.0366,  0.3943,  0.3616,  0.6830,  0.6282,\n",
      "         0.4178,  0.3641,  0.4603,  0.3404,  0.8286,  0.8389,  0.4732,  0.3855,\n",
      "         0.8889,  0.9134,  0.6873,  0.7037,  1.0179,  0.9774, -0.1129, -0.0971,\n",
      "         1.2212,  1.2437,  0.3248,  0.4114,  0.8786,  0.7778,  0.5796,  0.4960,\n",
      "        -0.1896, -0.1044,  1.2166,  1.2294,  0.6412,  0.5727,  0.7053,  0.7177,\n",
      "         0.5558,  0.5531, -0.1769, -0.1852,  0.4760,  0.4840,  1.0602,  1.0601,\n",
      "         0.7514,  0.7405,  1.0106,  0.9978,  0.6849,  0.7577,  0.8981,  0.8620,\n",
      "         0.5368,  0.5000,  0.4584,  0.4819,  0.3847,  0.3179,  0.5722,  0.5651,\n",
      "         0.3509,  0.2861,  0.6339,  0.6210,  0.8807,  0.8366,  0.7097,  0.5773,\n",
      "         0.7998,  0.8086,  0.7659,  0.7838,  1.2555,  1.3311,  0.8529,  0.8951,\n",
      "         1.0144,  0.9720,  1.1001,  1.0971,  0.6752,  0.6638,  1.0526,  1.0925,\n",
      "         0.9273,  0.9387,  1.1330,  1.1763,  1.0277,  1.0164,  0.7351,  0.7855,\n",
      "        -0.2537, -0.0520,  0.3248,  0.4114,  0.9946,  1.0612,  1.1442,  1.1567,\n",
      "         0.7053,  0.7455,  0.5880,  0.6623,  0.9824,  1.0163,  1.1963,  1.2177,\n",
      "         0.9612,  0.9195,  0.9003,  0.9023,  1.2606,  1.1925,  0.3191,  0.4028,\n",
      "         0.8587,  0.7798,  0.6878,  0.5544, -0.1315, -0.1298,  0.9200,  0.9464,\n",
      "         0.7880,  0.7981,  0.6999,  0.7331,  0.9513,  0.9843,  0.8124,  0.8059,\n",
      "        -0.2133, -0.1465,  0.4585,  0.4891,  0.6531,  0.6878,  0.6821,  0.7789,\n",
      "         0.9216,  0.9694,  0.5739,  0.5369,  0.8053,  0.7781,  1.0163,  1.0579,\n",
      "         1.0377,  1.1158,  0.7418,  0.6932,  1.1221,  1.0946,  0.6643,  0.6673,\n",
      "         0.4821,  0.5406,  0.9982,  1.0639,  0.4905,  0.4119,  1.0370,  1.0858,\n",
      "        -0.1818, -0.1161, -0.1574, -0.1478, -0.0942, -0.1055,  1.0722,  1.1117,\n",
      "         0.9227,  0.8798, -0.2148, -0.1206,  1.1601,  1.2510,  0.6212,  0.6623,\n",
      "         0.7796,  0.7016, -0.2375, -0.0811,  1.1195,  1.0896, -0.1827, -0.1481,\n",
      "         0.7112,  0.7043,  1.0140,  1.0347,  1.1183,  1.1458,  0.4534,  0.5441,\n",
      "         1.0679,  1.0636,  0.9219,  0.9390,  0.4679,  0.4003,  0.9568,  0.9981,\n",
      "         0.4738,  0.4721,  0.4244,  0.3894,  0.6988,  0.7146,  0.5130,  0.5100,\n",
      "         0.9153,  0.9296,  0.7627,  0.7218,  0.6445,  0.6576,  1.0833,  1.1353,\n",
      "         0.9750,  1.0244,  0.8862,  0.8229,  0.6423,  0.6503,  1.0842,  1.0822,\n",
      "         0.8634,  0.8981,  0.6988,  0.7112,  0.9269,  0.9662, -0.2033, -0.1594,\n",
      "         0.6424,  0.6806,  0.6821,  0.7789,  0.5221,  0.4059,  0.8796,  0.8875,\n",
      "         0.8235,  0.7303,  0.1719,  0.0979,  1.2790,  1.3252,  0.7156,  0.6871,\n",
      "         1.0913,  1.1091,  0.5937,  0.6144,  1.0824,  1.1065,  0.6224,  0.5829,\n",
      "         1.0209,  0.9907,  0.3333,  0.1979,  0.7248,  0.6604, -0.1331, -0.1808,\n",
      "         0.0999,  0.0548,  0.6780,  0.6620,  0.1370,  0.1739, -0.1356, -0.1082,\n",
      "         0.3700,  0.3703, -0.1256, -0.1601,  0.4881,  0.4790,  1.0628,  1.0501,\n",
      "         0.3598,  0.2217,  0.6157,  0.5988,  0.5258,  0.5077],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 라벨 값과 모델 예측 비교\n",
    "print()\n",
    "print('y:',y_train.flatten(),)\n",
    "print('predict:',model(x_train).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2189, 0.1555]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = [18,0,0,0,0,4,4,2,1,6]\n",
    "test_data = torch.FloatTensor([[18,0,0,0,0,4,4,2,1,6]])\n",
    "\n",
    "predict = model(test_data)\n",
    "predict # 인덱스 0이 크면 불합격, 인덱스 1이 크면 합격"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0490b6dc23274fc4b99f7f9728dd8f7f25e55907c8566e06726599f273a4cfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
